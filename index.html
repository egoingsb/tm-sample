<html>
<body style="background-color: white; color:black;">
    <div id="notice" style="font-size:300px; text-align: center; display:none;">그 손 당장 내려 놓으세요!!</div>
    <h1>습관교정 AI</h1>
    습관을 고칩시다!    
<ol>
    <li>웹캠을 준비합니다</li>    
    <li>teachablemachine에 접속합니다</li>
    <li>바꾸고 싶은 습관을 학습시킵니다.</li>    
    <li>웹캠이 자신을 바라보도록 합니다</li>    
</ol>

<br><br>

<div style="position: fixed; right:0; top:0;">
    <div id="webcam-container"></div>
    <div id="label-container"></div>
</div>

<img width="100%" src="https://images.unsplash.com/photo-1534131092884-4a0a9d19dff6?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1400&q=80" alt="">

<br><br>




<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
<script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    const URL = "https://teachablemachine.withgoogle.com/models/PyRQnYhEX/";

    let model, webcam, labelContainer, maxPredictions;

    let speech = new SpeechSynthesisUtterance();
    speech.lang = 'ko';
    speech.text = '그 손 당장 내려놓으세요!';
    

    // Load the image model and setup the webcam
    async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
    }

    async function predict() {
        // predict can take in an image, video or canvas html element
        const prediction = await model.predict(webcam.canvas);
        console.log(prediction, prediction[0].probability, prediction[1].probability);
        if(prediction[1].probability>0.8){
            document.querySelector('body').style.backgroundColor='red';
            document.querySelector('body').style.color='white';
            speechSynthesis.speak(speech);
            notice.style.display='block';
        } else {
            document.querySelector('body').style.backgroundColor='white';
            document.querySelector('body').style.color='black';
            speechSynthesis.cancel();
            notice.style.display='none';
        }
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ": " + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
    }

    init();
    
</script> 
</body>
</html>
